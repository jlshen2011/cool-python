{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and Preprocessing Data with TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import tarfile\n",
    "import urllib\n",
    "from tensorflow.train import FloatList, Feature, Example\n",
    "import tensorflow_transform as tft\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "plt.style.use(\"ggplot\")\n",
    "warnings.filterwarnings(action=\"ignore\")\n",
    "os.chdir('datasets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Data API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: (), types: tf.int32>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = tf.range(10)\n",
    "dataset = tf.data.Dataset.from_tensor_slices(X)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equivalently:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(2, shape=(), dtype=int64)\n",
      "tf.Tensor(3, shape=(), dtype=int64)\n",
      "tf.Tensor(4, shape=(), dtype=int64)\n",
      "tf.Tensor(5, shape=(), dtype=int64)\n",
      "tf.Tensor(6, shape=(), dtype=int64)\n",
      "tf.Tensor(7, shape=(), dtype=int64)\n",
      "tf.Tensor(8, shape=(), dtype=int64)\n",
      "tf.Tensor(9, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.range(10)\n",
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "raises-exception"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0 1 2 3 4 5 6], shape=(7,), dtype=int64)\n",
      "tf.Tensor([7 8 9 0 1 2 3], shape=(7,), dtype=int64)\n",
      "tf.Tensor([4 5 6 7 8 9 0], shape=(7,), dtype=int64)\n",
      "tf.Tensor([1 2 3 4 5 6 7], shape=(7,), dtype=int64)\n",
      "tf.Tensor([8 9], shape=(2,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.repeat(3).batch(7)\n",
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 0  2  4  6  8 10 12], shape=(7,), dtype=int64)\n",
      "tf.Tensor([14 16 18  0  2  4  6], shape=(7,), dtype=int64)\n",
      "tf.Tensor([ 8 10 12 14 16 18  0], shape=(7,), dtype=int64)\n",
      "tf.Tensor([ 2  4  6  8 10 12 14], shape=(7,), dtype=int64)\n",
      "tf.Tensor([16 18], shape=(2,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.map(lambda x: x * 2)\n",
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0, shape=(), dtype=int64)\n",
      "tf.Tensor(2, shape=(), dtype=int64)\n",
      "tf.Tensor(4, shape=(), dtype=int64)\n",
      "tf.Tensor(6, shape=(), dtype=int64)\n",
      "tf.Tensor(8, shape=(), dtype=int64)\n",
      "tf.Tensor(10, shape=(), dtype=int64)\n",
      "tf.Tensor(12, shape=(), dtype=int64)\n",
      "tf.Tensor(14, shape=(), dtype=int64)\n",
      "tf.Tensor(16, shape=(), dtype=int64)\n",
      "tf.Tensor(18, shape=(), dtype=int64)\n",
      "tf.Tensor(0, shape=(), dtype=int64)\n",
      "tf.Tensor(2, shape=(), dtype=int64)\n",
      "tf.Tensor(4, shape=(), dtype=int64)\n",
      "tf.Tensor(6, shape=(), dtype=int64)\n",
      "tf.Tensor(8, shape=(), dtype=int64)\n",
      "tf.Tensor(10, shape=(), dtype=int64)\n",
      "tf.Tensor(12, shape=(), dtype=int64)\n",
      "tf.Tensor(14, shape=(), dtype=int64)\n",
      "tf.Tensor(16, shape=(), dtype=int64)\n",
      "tf.Tensor(18, shape=(), dtype=int64)\n",
      "tf.Tensor(0, shape=(), dtype=int64)\n",
      "tf.Tensor(2, shape=(), dtype=int64)\n",
      "tf.Tensor(4, shape=(), dtype=int64)\n",
      "tf.Tensor(6, shape=(), dtype=int64)\n",
      "tf.Tensor(8, shape=(), dtype=int64)\n",
      "tf.Tensor(10, shape=(), dtype=int64)\n",
      "tf.Tensor(12, shape=(), dtype=int64)\n",
      "tf.Tensor(14, shape=(), dtype=int64)\n",
      "tf.Tensor(16, shape=(), dtype=int64)\n",
      "tf.Tensor(18, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.unbatch()\n",
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0, shape=(), dtype=int64)\n",
      "tf.Tensor(2, shape=(), dtype=int64)\n",
      "tf.Tensor(4, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.filter(lambda x: x < 10)  # keep only items < 10\n",
    "for item in dataset.take(3):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0 3 4 2 1 5 8], shape=(7,), dtype=int64)\n",
      "tf.Tensor([6 9 7 2 3 1 4], shape=(7,), dtype=int64)\n",
      "tf.Tensor([6 0 7 9 0 1 2], shape=(7,), dtype=int64)\n",
      "tf.Tensor([8 4 5 5 3 8 9], shape=(7,), dtype=int64)\n",
      "tf.Tensor([7 6], shape=(2,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.range(10).repeat(3)\n",
    "dataset = dataset.shuffle(buffer_size=3, seed=42).batch(7)\n",
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the California dataset to multiple CSV files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by loading and preparing the California housing dataset. We first load it, then split it into a training set, a validation set and a test set, and finally we scale it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    housing.data, housing.target.reshape(-1, 1), random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_mean = scaler.mean_\n",
    "X_std = scaler.scale_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a very large dataset that does not fit in memory, you will typically want to split it into many files first, then have TensorFlow read these files in parallel. To demonstrate this, let's start by splitting the housing dataset and save it to 20 CSV files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_multiple_csv_files(data, name_prefix, header=None, n_parts=10):\n",
    "    housing_dir = os.path.join(\"datasets\", \"housing\")\n",
    "    os.makedirs(housing_dir, exist_ok=True)\n",
    "    path_format = os.path.join(housing_dir, \"my_{}_{:02d}.csv\")\n",
    "\n",
    "    filepaths = []\n",
    "    m = len(data)\n",
    "    for file_idx, row_indices in enumerate(np.array_split(np.arange(m), n_parts)):\n",
    "        part_csv = path_format.format(name_prefix, file_idx)\n",
    "        filepaths.append(part_csv)\n",
    "        with open(part_csv, \"wt\", encoding=\"utf-8\") as f:\n",
    "            if header is not None:\n",
    "                f.write(header)\n",
    "                f.write(\"\\n\")\n",
    "            for row_idx in row_indices:\n",
    "                f.write(\",\".join([repr(col) for col in data[row_idx]]))\n",
    "                f.write(\"\\n\")\n",
    "    return filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.c_[X_train, y_train]\n",
    "valid_data = np.c_[X_valid, y_valid]\n",
    "test_data = np.c_[X_test, y_test]\n",
    "header_cols = housing.feature_names + [\"MedianHouseValue\"]\n",
    "header = \",\".join(header_cols)\n",
    "\n",
    "train_filepaths = save_to_multiple_csv_files(train_data, \"train\", header, n_parts=20)\n",
    "valid_filepaths = save_to_multiple_csv_files(valid_data, \"valid\", header, n_parts=10)\n",
    "test_filepaths = save_to_multiple_csv_files(test_data, \"test\", header, n_parts=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, now let's take a peek at the first few lines of one of these CSV files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>MedianHouseValue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.5214</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.049945</td>\n",
       "      <td>1.106548</td>\n",
       "      <td>1447.0</td>\n",
       "      <td>1.605993</td>\n",
       "      <td>37.63</td>\n",
       "      <td>-122.43</td>\n",
       "      <td>1.442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.3275</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.490060</td>\n",
       "      <td>0.991054</td>\n",
       "      <td>3464.0</td>\n",
       "      <td>3.443340</td>\n",
       "      <td>33.69</td>\n",
       "      <td>-117.39</td>\n",
       "      <td>1.687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.1000</td>\n",
       "      <td>29.0</td>\n",
       "      <td>7.542373</td>\n",
       "      <td>1.591525</td>\n",
       "      <td>1328.0</td>\n",
       "      <td>2.250847</td>\n",
       "      <td>38.44</td>\n",
       "      <td>-122.98</td>\n",
       "      <td>1.621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.1736</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.289003</td>\n",
       "      <td>0.997442</td>\n",
       "      <td>1054.0</td>\n",
       "      <td>2.695652</td>\n",
       "      <td>33.55</td>\n",
       "      <td>-117.70</td>\n",
       "      <td>2.621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0549</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.312457</td>\n",
       "      <td>1.085092</td>\n",
       "      <td>3297.0</td>\n",
       "      <td>2.244384</td>\n",
       "      <td>33.93</td>\n",
       "      <td>-116.93</td>\n",
       "      <td>0.956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  3.5214      15.0  3.049945   1.106548      1447.0  1.605993     37.63   \n",
       "1  5.3275       5.0  6.490060   0.991054      3464.0  3.443340     33.69   \n",
       "2  3.1000      29.0  7.542373   1.591525      1328.0  2.250847     38.44   \n",
       "3  7.1736      12.0  6.289003   0.997442      1054.0  2.695652     33.55   \n",
       "4  2.0549      13.0  5.312457   1.085092      3297.0  2.244384     33.93   \n",
       "\n",
       "   Longitude  MedianHouseValue  \n",
       "0    -122.43             1.442  \n",
       "1    -117.39             1.687  \n",
       "2    -122.98             1.621  \n",
       "3    -117.70             2.621  \n",
       "4    -116.93             0.956  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(train_filepaths[0]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or in text mode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MedInc,HouseAge,AveRooms,AveBedrms,Population,AveOccup,Latitude,Longitude,MedianHouseValue\n",
      "3.5214,15.0,3.0499445061043287,1.106548279689234,1447.0,1.6059933407325193,37.63,-122.43,1.442\n",
      "5.3275,5.0,6.490059642147117,0.9910536779324056,3464.0,3.4433399602385686,33.69,-117.39,1.687\n",
      "3.1,29.0,7.5423728813559325,1.5915254237288134,1328.0,2.2508474576271187,38.44,-122.98,1.621\n",
      "7.1736,12.0,6.289002557544757,0.9974424552429667,1054.0,2.6956521739130435,33.55,-117.7,2.621\n"
     ]
    }
   ],
   "source": [
    "with open(train_filepaths[0]) as f:\n",
    "    for i in range(5):\n",
    "        print(f.readline(), end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['datasets/housing/my_train_00.csv',\n",
       " 'datasets/housing/my_train_01.csv',\n",
       " 'datasets/housing/my_train_02.csv',\n",
       " 'datasets/housing/my_train_03.csv',\n",
       " 'datasets/housing/my_train_04.csv',\n",
       " 'datasets/housing/my_train_05.csv',\n",
       " 'datasets/housing/my_train_06.csv',\n",
       " 'datasets/housing/my_train_07.csv',\n",
       " 'datasets/housing/my_train_08.csv',\n",
       " 'datasets/housing/my_train_09.csv',\n",
       " 'datasets/housing/my_train_10.csv',\n",
       " 'datasets/housing/my_train_11.csv',\n",
       " 'datasets/housing/my_train_12.csv',\n",
       " 'datasets/housing/my_train_13.csv',\n",
       " 'datasets/housing/my_train_14.csv',\n",
       " 'datasets/housing/my_train_15.csv',\n",
       " 'datasets/housing/my_train_16.csv',\n",
       " 'datasets/housing/my_train_17.csv',\n",
       " 'datasets/housing/my_train_18.csv',\n",
       " 'datasets/housing/my_train_19.csv']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_filepaths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building an Input Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_dataset = tf.data.Dataset.list_files(train_filepaths, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'datasets/housing/my_train_05.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets/housing/my_train_16.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets/housing/my_train_01.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets/housing/my_train_17.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets/housing/my_train_00.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets/housing/my_train_14.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets/housing/my_train_10.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets/housing/my_train_02.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets/housing/my_train_12.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets/housing/my_train_19.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets/housing/my_train_07.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets/housing/my_train_09.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets/housing/my_train_13.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets/housing/my_train_15.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets/housing/my_train_11.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets/housing/my_train_18.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets/housing/my_train_04.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets/housing/my_train_06.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets/housing/my_train_03.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets/housing/my_train_08.csv', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "for filepath in filepath_dataset:\n",
    "    print(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda filepath: tf.data.TextLineDataset(filepath).skip(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_readers = 5\n",
    "dataset = filepath_dataset.interleave(f, cycle_length=n_readers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'4.5909,16.0,5.475877192982456,1.0964912280701755,1357.0,2.9758771929824563,33.63,-117.71,2.418'\n",
      "b'2.4792,24.0,3.4547038327526134,1.1341463414634145,2251.0,3.921602787456446,34.18,-118.38,2.0'\n",
      "b'4.2708,45.0,5.121387283236994,0.953757225433526,492.0,2.8439306358381504,37.48,-122.19,2.67'\n",
      "b'2.1856,41.0,3.7189873417721517,1.0658227848101265,803.0,2.0329113924050635,32.76,-117.12,1.205'\n",
      "b'4.1812,52.0,5.701388888888889,0.9965277777777778,692.0,2.4027777777777777,33.73,-118.31,3.215'\n",
      "b'3.6548,29.0,4.6434540389972145,0.9916434540389972,2919.0,4.0654596100278555,34.3,-118.42,1.803'\n",
      "b'3.9543,35.0,5.134122287968442,0.9506903353057199,1305.0,2.57396449704142,33.94,-118.0,2.144'\n",
      "b'4.7426,19.0,5.871428571428571,1.022857142857143,1064.0,3.04,37.93,-121.66,2.631'\n",
      "b'5.3344,12.0,7.594235033259423,1.2172949002217295,1357.0,3.008869179600887,38.58,-121.0,2.175'\n",
      "b'4.4474,25.0,6.342776203966006,1.0226628895184136,928.0,2.6288951841359776,38.03,-122.26,2.037'\n"
     ]
    }
   ],
   "source": [
    "for line in dataset.take(10):\n",
    "    print(line.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that field 4 is interpreted as a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=int32, numpy=1>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.0>,\n",
       " <tf.Tensor: shape=(), dtype=float64, numpy=3.0>,\n",
       " <tf.Tensor: shape=(), dtype=string, numpy=b'4'>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.0>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record_defaults=[0, np.nan, tf.constant(np.nan, dtype=tf.float64), \"Hello\", tf.constant([])]\n",
    "parsed_fields = tf.io.decode_csv('1,2,3,4,5', record_defaults)\n",
    "parsed_fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that all missing fields are replaced with their default value, when provided:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=int32, numpy=0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=nan>,\n",
       " <tf.Tensor: shape=(), dtype=float64, numpy=nan>,\n",
       " <tf.Tensor: shape=(), dtype=string, numpy=b'Hello'>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.0>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_fields = tf.io.decode_csv(',,,,5', record_defaults)\n",
    "parsed_fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 5th field is compulsory (since we provided `tf.constant([])` as the \"default value\"), so we get an exception if we do not provide it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Field 4 is required but missing in record 0! [Op:DecodeCSV]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    parsed_fields = tf.io.decode_csv(',,,,', record_defaults)\n",
    "except tf.errors.InvalidArgumentError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of fields should match exactly the number of fields in the `record_defaults`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expect 5 fields but have 7 in record 0 [Op:DecodeCSV]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    parsed_fields = tf.io.decode_csv('1,2,3,4,5,6,7', record_defaults)\n",
    "except tf.errors.InvalidArgumentError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = 8 # X_train.shape[-1]\n",
    "\n",
    "@tf.function\n",
    "def preprocess(line):\n",
    "    defs = [0.] * n_inputs + [tf.constant([], dtype=tf.float32)]\n",
    "    fields = tf.io.decode_csv(line, record_defaults=defs)\n",
    "    x = tf.stack(fields[:-1])\n",
    "    y = tf.stack(fields[-1:])\n",
    "    return (x - X_mean) / X_std, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8,), dtype=float32, numpy=\n",
       " array([ 0.16579157,  1.216324  , -0.05204565, -0.39215982, -0.5277444 ,\n",
       "        -0.2633488 ,  0.8543046 , -1.3072058 ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1,), dtype=float32, numpy=array([2.782], dtype=float32)>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess(b'4.2083,44.0,5.3232,0.9171,846.0,2.3370,37.47,-122.2,2.782')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_reader_dataset(filepaths, repeat=1, n_readers=5,\n",
    "                       n_read_threads=None, shuffle_buffer_size=10000,\n",
    "                       n_parse_threads=5, batch_size=32):\n",
    "    dataset = tf.data.Dataset.list_files(filepaths).repeat(repeat)\n",
    "    dataset = dataset.interleave(\n",
    "        lambda filepath: tf.data.TextLineDataset(filepath).skip(1),\n",
    "        cycle_length=n_readers, num_parallel_calls=n_read_threads)\n",
    "    dataset = dataset.shuffle(shuffle_buffer_size)\n",
    "    dataset = dataset.map(preprocess, num_parallel_calls=n_parse_threads)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset.prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = tf.Tensor(\n",
      "[[ 0.5804519  -0.20762321  0.05616303 -0.15191229  0.01343246  0.00604472\n",
      "   1.2525111  -1.3671792 ]\n",
      " [ 5.818099    1.8491895   1.1784915   0.28173092 -1.2496178  -0.3571987\n",
      "   0.7231292  -1.0023477 ]\n",
      " [-0.9253566   0.5834586  -0.7807257  -0.28213993 -0.36530012  0.27389365\n",
      "  -0.76194876  0.72684526]], shape=(3, 8), dtype=float32)\n",
      "y = tf.Tensor(\n",
      "[[1.752]\n",
      " [1.313]\n",
      " [1.535]], shape=(3, 1), dtype=float32)\n",
      "\n",
      "X = tf.Tensor(\n",
      "[[-0.8324941   0.6625668  -0.20741376 -0.18699841 -0.14536144  0.09635526\n",
      "   0.9807942  -0.67250353]\n",
      " [-0.62183803  0.5834586  -0.19862501 -0.3500319  -1.1437552  -0.3363751\n",
      "   1.107282   -0.8674123 ]\n",
      " [ 0.8683102   0.02970133  0.3427381  -0.29872298  0.7124906   0.28026953\n",
      "  -0.72915536  0.86178064]], shape=(3, 8), dtype=float32)\n",
      "y = tf.Tensor(\n",
      "[[0.919]\n",
      " [1.028]\n",
      " [2.182]], shape=(3, 1), dtype=float32)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "train_set = csv_reader_dataset(train_filepaths, batch_size=3)\n",
    "for X_batch, y_batch in train_set.take(2):\n",
    "    print(\"X =\", X_batch)\n",
    "    print(\"y =\", y_batch)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = csv_reader_dataset(train_filepaths, repeat=None)\n",
    "valid_set = csv_reader_dataset(valid_filepaths)\n",
    "test_set = csv_reader_dataset(test_filepaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fcdb4067950>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "model.fit(train_set, steps_per_epoch=len(X_train) // batch_size, epochs=10, verbose=0,\n",
    "          validation_data=valid_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161/161 [==============================] - 0s 852us/step - loss: 0.4788\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4787752032279968"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_set, steps=len(X_test) // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.3576405],\n",
       "       [2.255291 ],\n",
       "       [1.4437604],\n",
       "       ...,\n",
       "       [0.5654393],\n",
       "       [3.9442453],\n",
       "       [1.0232248]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_set = test_set.map(lambda X, y: X) # we could instead just pass test_set, Keras would ignore the labels\n",
    "X_new = X_test\n",
    "model.predict(new_set, steps=len(X_new) // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global step 1810/1810"
     ]
    }
   ],
   "source": [
    "optimizer = keras.optimizers.Nadam(lr=0.01)\n",
    "loss_fn = keras.losses.mean_squared_error\n",
    "\n",
    "n_epochs = 5\n",
    "batch_size = 32\n",
    "n_steps_per_epoch = len(X_train) // batch_size\n",
    "total_steps = n_epochs * n_steps_per_epoch\n",
    "global_step = 0\n",
    "for X_batch, y_batch in train_set.take(total_steps):\n",
    "    global_step += 1\n",
    "    print(\"\\rGlobal step {}/{}\".format(global_step, total_steps), end=\"\")\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = model(X_batch)\n",
    "        main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
    "        loss = tf.add_n([main_loss] + model.losses)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Nadam(lr=0.01)\n",
    "loss_fn = keras.losses.mean_squared_error\n",
    "\n",
    "@tf.function\n",
    "def train(model, n_epochs, batch_size=32,\n",
    "          n_readers=5, n_read_threads=5, shuffle_buffer_size=10000, n_parse_threads=5):\n",
    "    train_set = csv_reader_dataset(train_filepaths, repeat=n_epochs, n_readers=n_readers,\n",
    "                       n_read_threads=n_read_threads, shuffle_buffer_size=shuffle_buffer_size,\n",
    "                       n_parse_threads=n_parse_threads, batch_size=batch_size)\n",
    "    for X_batch, y_batch in train_set:\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = model(X_batch)\n",
    "            main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
    "            loss = tf.add_n([main_loss] + model.losses)\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "train(model, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global step 100 / 1810\n",
      "Global step 200 / 1810\n",
      "Global step 300 / 1810\n",
      "Global step 400 / 1810\n",
      "Global step 500 / 1810\n",
      "Global step 600 / 1810\n",
      "Global step 700 / 1810\n",
      "Global step 800 / 1810\n",
      "Global step 900 / 1810\n",
      "Global step 1000 / 1810\n",
      "Global step 1100 / 1810\n",
      "Global step 1200 / 1810\n",
      "Global step 1300 / 1810\n",
      "Global step 1400 / 1810\n",
      "Global step 1500 / 1810\n",
      "Global step 1600 / 1810\n",
      "Global step 1700 / 1810\n",
      "Global step 1800 / 1810\n"
     ]
    }
   ],
   "source": [
    "optimizer = keras.optimizers.Nadam(lr=0.01)\n",
    "loss_fn = keras.losses.mean_squared_error\n",
    "\n",
    "@tf.function\n",
    "def train(model, n_epochs, batch_size=32,\n",
    "          n_readers=5, n_read_threads=5, shuffle_buffer_size=10000, n_parse_threads=5):\n",
    "    train_set = csv_reader_dataset(train_filepaths, repeat=n_epochs, n_readers=n_readers,\n",
    "                       n_read_threads=n_read_threads, shuffle_buffer_size=shuffle_buffer_size,\n",
    "                       n_parse_threads=n_parse_threads, batch_size=batch_size)\n",
    "    n_steps_per_epoch = len(X_train) // batch_size\n",
    "    total_steps = n_epochs * n_steps_per_epoch\n",
    "    global_step = 0\n",
    "    for X_batch, y_batch in train_set.take(total_steps):\n",
    "        global_step += 1\n",
    "        if tf.equal(global_step % 100, 0):\n",
    "            tf.print(\"\\rGlobal step\", global_step, \"/\", total_steps)\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = model(X_batch)\n",
    "            main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
    "            loss = tf.add_n([main_loss] + model.losses)\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "train(model, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a short description of each method in the `Dataset` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "● apply()              Applies a transformation function to this dataset.\n",
      "● as_numpy_iterator()  Returns an iterator which converts all elements of the dataset to numpy.\n",
      "● batch()              Combines consecutive elements of this dataset into batches.\n",
      "● cache()              Caches the elements in this dataset.\n",
      "● concatenate()        Creates a `Dataset` by concatenating the given dataset with this dataset.\n",
      "● element_spec()       The type specification of an element of this dataset.\n",
      "● enumerate()          Enumerates the elements of this dataset.\n",
      "● filter()             Filters this dataset according to `predicate`.\n",
      "● flat_map()           Maps `map_func` across this dataset and flattens the result.\n",
      "● from_generator()     Creates a `Dataset` whose elements are generated by `generator`.\n",
      "● from_tensor_slices() Creates a `Dataset` whose elements are slices of the given tensors.\n",
      "● from_tensors()       Creates a `Dataset` with a single element, comprising the given tensors.\n",
      "● interleave()         Maps `map_func` across this dataset, and interleaves the results.\n",
      "● list_files()         A dataset of all files matching one or more glob patterns.\n",
      "● map()                Maps `map_func` across the elements of this dataset.\n",
      "● options()            Returns the options for this dataset and its inputs.\n",
      "● padded_batch()       Combines consecutive elements of this dataset into padded batches.\n",
      "● prefetch()           Creates a `Dataset` that prefetches elements from this dataset.\n",
      "● range()              Creates a `Dataset` of a step-separated range of values.\n",
      "● reduce()             Reduces the input dataset to a single element.\n",
      "● repeat()             Repeats this dataset so each original value is seen `count` times.\n",
      "● shard()              Creates a `Dataset` that includes only 1/`num_shards` of this dataset.\n",
      "● shuffle()            Randomly shuffles the elements of this dataset.\n",
      "● skip()               Creates a `Dataset` that skips `count` elements from this dataset.\n",
      "● take()               Creates a `Dataset` with at most `count` elements from this dataset.\n",
      "● unbatch()            Splits elements of a dataset into multiple elements.\n",
      "● window()             Combines (nests of) input elements into a dataset of (nests of) windows.\n",
      "● with_options()       Returns a new `tf.data.Dataset` with the given options set.\n",
      "● zip()                Creates a `Dataset` by zipping together the given datasets.\n"
     ]
    }
   ],
   "source": [
    "for m in dir(tf.data.Dataset):\n",
    "    if not (m.startswith(\"_\") or m.endswith(\"_\")):\n",
    "        func = getattr(tf.data.Dataset, m)\n",
    "        if hasattr(func, \"__doc__\"):\n",
    "            print(\"● {:21s}{}\".format(m + \"()\", func.__doc__.split(\"\\n\")[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Features API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/ageron/handson-ml2/master/\"\n",
    "HOUSING_PATH = os.path.join(\"datasets\", \"housing\")\n",
    "HOUSING_URL = DOWNLOAD_ROOT + \"datasets/housing/housing.tgz\"\n",
    "\n",
    "def fetch_housing_data(housing_url=HOUSING_URL, housing_path=HOUSING_PATH):\n",
    "    os.makedirs(housing_path, exist_ok=True)\n",
    "    tgz_path = os.path.join(housing_path, \"housing.tgz\")\n",
    "    urllib.request.urlretrieve(housing_url, tgz_path)\n",
    "    housing_tgz = tarfile.open(tgz_path)\n",
    "    housing_tgz.extractall(path=housing_path)\n",
    "    housing_tgz.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_housing_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_housing_data(housing_path=HOUSING_PATH):\n",
    "    csv_path = os.path.join(housing_path, \"housing.csv\")\n",
    "    return pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>ocean_proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-122.23</td>\n",
       "      <td>37.88</td>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-122.22</td>\n",
       "      <td>37.86</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-122.24</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>352100.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>341300.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>342200.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0    -122.23     37.88                41.0        880.0           129.0   \n",
       "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
       "2    -122.24     37.85                52.0       1467.0           190.0   \n",
       "3    -122.25     37.85                52.0       1274.0           235.0   \n",
       "4    -122.25     37.85                52.0       1627.0           280.0   \n",
       "\n",
       "   population  households  median_income  median_house_value ocean_proximity  \n",
       "0       322.0       126.0         8.3252            452600.0        NEAR BAY  \n",
       "1      2401.0      1138.0         8.3014            358500.0        NEAR BAY  \n",
       "2       496.0       177.0         7.2574            352100.0        NEAR BAY  \n",
       "3       558.0       219.0         5.6431            341300.0        NEAR BAY  \n",
       "4       565.0       259.0         3.8462            342200.0        NEAR BAY  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing = load_housing_data()\n",
    "housing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_median_age = tf.feature_column.numeric_column(\"housing_median_age\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_mean, age_std = X_mean[1], X_std[1]  # The median age is column in 1\n",
    "housing_median_age = tf.feature_column.numeric_column(\n",
    "    \"housing_median_age\", normalizer_fn=lambda x: (x - age_mean) / age_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_income = tf.feature_column.numeric_column(\"median_income\")\n",
    "bucketized_income = tf.feature_column.bucketized_column(\n",
    "    median_income, boundaries=[1.5, 3., 4.5, 6.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BucketizedColumn(source_column=NumericColumn(key='median_income', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), boundaries=(1.5, 3.0, 4.5, 6.0))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucketized_income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocean_prox_vocab = ['<1H OCEAN', 'INLAND', 'ISLAND', 'NEAR BAY', 'NEAR OCEAN']\n",
    "ocean_proximity = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "    \"ocean_proximity\", ocean_prox_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VocabularyListCategoricalColumn(key='ocean_proximity', vocabulary_list=('<1H OCEAN', 'INLAND', 'ISLAND', 'NEAR BAY', 'NEAR OCEAN'), dtype=tf.string, default_value=-1, num_oov_buckets=0)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ocean_proximity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HashedCategoricalColumn(key='city', hash_bucket_size=1000, dtype=tf.string)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just an example, it's not used later on\n",
    "city_hash = tf.feature_column.categorical_column_with_hash_bucket(\n",
    "    \"city\", hash_bucket_size=1000)\n",
    "city_hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucketized_age = tf.feature_column.bucketized_column(\n",
    "    housing_median_age, boundaries=[-1., -0.5, 0., 0.5, 1.]) # age was scaled\n",
    "age_and_ocean_proximity = tf.feature_column.crossed_column(\n",
    "    [bucketized_age, ocean_proximity], hash_bucket_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "latitude = tf.feature_column.numeric_column(\"latitude\")\n",
    "longitude = tf.feature_column.numeric_column(\"longitude\")\n",
    "bucketized_latitude = tf.feature_column.bucketized_column(\n",
    "    latitude, boundaries=list(np.linspace(32., 42., 20 - 1)))\n",
    "bucketized_longitude = tf.feature_column.bucketized_column(\n",
    "    longitude, boundaries=list(np.linspace(-125., -114., 20 - 1)))\n",
    "location = tf.feature_column.crossed_column(\n",
    "    [bucketized_latitude, bucketized_longitude], hash_bucket_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocean_proximity_one_hot = tf.feature_column.indicator_column(ocean_proximity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocean_proximity_embed = tf.feature_column.embedding_column(ocean_proximity,\n",
    "                                                           dimension=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Feature Columns for Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_house_value = tf.feature_column.numeric_column(\"median_house_value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'housing_median_age': FixedLenFeature(shape=(1,), dtype=tf.float32, default_value=None),\n",
       " 'median_house_value': FixedLenFeature(shape=(1,), dtype=tf.float32, default_value=None)}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = [housing_median_age, median_house_value]\n",
    "feature_descriptions = tf.feature_column.make_parse_example_spec(columns)\n",
    "feature_descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.io.TFRecordWriter(\"my_data_with_features.tfrecords\") as f:\n",
    "    for x, y in zip(X_train[:, 1:2], y_train):\n",
    "        example = Example(features=tf.train.Features(feature={\n",
    "            \"housing_median_age\": Feature(float_list=FloatList(value=[x])),\n",
    "            \"median_house_value\": Feature(float_list=FloatList(value=[y]))\n",
    "        }))\n",
    "        f.write(example.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_examples(serialized_examples):\n",
    "    examples = tf.io.parse_example(serialized_examples, feature_descriptions)\n",
    "    targets = examples.pop(\"median_house_value\") # separate the targets\n",
    "    return examples, targets\n",
    "\n",
    "batch_size = 32\n",
    "dataset = tf.data.TFRecordDataset([\"my_data_with_features.tfrecords\"])\n",
    "dataset = dataset.repeat().shuffle(10000).batch(batch_size).map(parse_examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Warning**: the `DenseFeatures` layer currently does not work with the Functional API, see [TF issue #27416](https://github.com/tensorflow/tensorflow/issues/27416). Hopefully this will be resolved before the final release of TF 2.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "362/362 [==============================] - 0s 716us/step - loss: 3.9083 - accuracy: 0.0016\n",
      "Epoch 2/5\n",
      "362/362 [==============================] - 0s 702us/step - loss: 1.9228 - accuracy: 0.0020\n",
      "Epoch 3/5\n",
      "362/362 [==============================] - 0s 698us/step - loss: 1.4706 - accuracy: 0.0029\n",
      "Epoch 4/5\n",
      "362/362 [==============================] - 0s 698us/step - loss: 1.3730 - accuracy: 0.0035\n",
      "Epoch 5/5\n",
      "362/362 [==============================] - 0s 709us/step - loss: 1.3145 - accuracy: 0.0027\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fcd9535b590>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_without_target = columns[:-1]\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.DenseFeatures(feature_columns=columns_without_target),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(loss=\"mse\",\n",
    "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(dataset, steps_per_epoch=len(X_train) // batch_size, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 7), dtype=float32, numpy=\n",
       "array([[ 0.        ,  0.        ,  1.        ,  0.        ,  0.        ,\n",
       "        -1.2252209 , -0.06296062],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  1.        ,\n",
       "        -0.52398515,  0.84748596],\n",
       "       [ 1.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        -0.52398515,  0.84748596]], dtype=float32)>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_columns = [ocean_proximity_embed, bucketized_income]\n",
    "dense_features = keras.layers.DenseFeatures(some_columns)\n",
    "dense_features({\n",
    "    \"ocean_proximity\": [[\"NEAR OCEAN\"], [\"INLAND\"], [\"INLAND\"]],\n",
    "    \"median_income\": [[3.], [7.2], [1.]]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(inputs):  # inputs is a batch of input features\n",
    "    median_age = inputs[\"housing_median_age\"]\n",
    "    ocean_proximity = inputs[\"ocean_proximity\"]\n",
    "    standardized_age = tft.scale_to_z_score(median_age - tft.mean(median_age))\n",
    "    ocean_proximity_id = tft.compute_and_apply_vocabulary(ocean_proximity)\n",
    "    return {\n",
    "        \"standardized_median_age\": standardized_age,\n",
    "        \"ocean_proximity_id\": ocean_proximity_id\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = tfds.load(name=\"mnist\")\n",
    "mnist_train, mnist_test = datasets[\"train\"], datasets[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abstract_reasoning', 'aeslc', 'aflw2k3d', 'amazon_us_reviews', 'bair_robot_pushing_small', 'big_patent', 'bigearthnet', 'billsum', 'binarized_mnist', 'binary_alpha_digits', 'c4', 'caltech101', 'caltech_birds2010', 'caltech_birds2011', 'cars196', 'cassava', 'cats_vs_dogs', 'celeb_a', 'celeb_a_hq', 'chexpert', 'cifar10', 'cifar100', 'cifar10_1', 'cifar10_corrupted', 'citrus_leaves', 'clevr', 'cmaterdb', 'cnn_dailymail', 'coco', 'coil100', 'colorectal_histology', 'colorectal_histology_large', 'curated_breast_imaging_ddsm', 'cycle_gan', 'deep_weeds', 'definite_pronoun_resolution', 'diabetic_retinopathy_detection', 'dmlab', 'downsampled_imagenet', 'dsprites', 'dtd', 'duke_ultrasound', 'dummy_dataset_shared_generator', 'dummy_mnist', 'emnist', 'esnli', 'eurosat', 'fashion_mnist', 'flores', 'food101', 'gap', 'gigaword', 'glue', 'groove', 'higgs', 'horses_or_humans', 'i_naturalist2017', 'image_label_folder', 'imagenet2012', 'imagenet2012_corrupted', 'imagenet_resized', 'imdb_reviews', 'iris', 'kitti', 'kmnist', 'lfw', 'lm1b', 'lost_and_found', 'lsun', 'malaria', 'math_dataset', 'mnist', 'mnist_corrupted', 'moving_mnist', 'multi_news', 'multi_nli', 'multi_nli_mismatch', 'newsroom', 'nsynth', 'omniglot', 'open_images_v4', 'oxford_flowers102', 'oxford_iiit_pet', 'para_crawl', 'patch_camelyon', 'pet_finder', 'places365_small', 'plant_leaves', 'plant_village', 'plantae_k', 'quickdraw_bitmap', 'reddit_tifu', 'resisc45', 'rock_paper_scissors', 'rock_you', 'scene_parse150', 'scicite', 'scientific_papers', 'shapes3d', 'smallnorb', 'snli', 'so2sat', 'squad', 'stanford_dogs', 'stanford_online_products', 'starcraft_video', 'sun397', 'super_glue', 'svhn_cropped', 'ted_hrlr_translate', 'ted_multi_translate', 'tf_flowers', 'the300w_lp', 'titanic', 'trivia_qa', 'uc_merced', 'ucf101', 'visual_domain_decathlon', 'voc', 'wider_face', 'wikihow', 'wikipedia', 'wmt14_translate', 'wmt15_translate', 'wmt16_translate', 'wmt17_translate', 'wmt18_translate', 'wmt19_translate', 'wmt_t2t_translate', 'wmt_translate', 'xnli', 'xsum']\n"
     ]
    }
   ],
   "source": [
    "print(tfds.list_builders())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x216 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6,3))\n",
    "mnist_train = mnist_train.repeat(5).batch(32).prefetch(1)\n",
    "for item in mnist_train:\n",
    "    images = item[\"image\"]\n",
    "    labels = item[\"label\"]\n",
    "    for index in range(5):\n",
    "        plt.subplot(1, 5, index + 1)\n",
    "        image = images[index, ..., 0]\n",
    "        label = labels[index].numpy()\n",
    "        plt.imshow(image, cmap=\"binary\")\n",
    "        plt.title(label)\n",
    "        plt.axis(\"off\")\n",
    "    break # just showing part of the first batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 28, 28, 1)\n",
      "[8 8 3 0 0 4 0 6 1 1 7 1 9 5 0 6 1 2 0 1 9 4 3 0 4 6 6 8 3 4 0 3]\n"
     ]
    }
   ],
   "source": [
    "datasets = tfds.load(name=\"mnist\")\n",
    "mnist_train, mnist_test = datasets[\"train\"], datasets[\"test\"]\n",
    "mnist_train = mnist_train.repeat(5).batch(32)\n",
    "mnist_train = mnist_train.map(lambda items: (items[\"image\"], items[\"label\"]))\n",
    "mnist_train = mnist_train.prefetch(1)\n",
    "for images, labels in mnist_train.take(1):\n",
    "    print(images.shape)\n",
    "    print(labels.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fcd96d4de50>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets = tfds.load(name=\"mnist\", batch_size=32, as_supervised=True)\n",
    "mnist_train = datasets[\"train\"].repeat().prefetch(1)\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28, 1]),\n",
    "    keras.layers.Lambda(lambda images: tf.cast(images, tf.float32)),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(mnist_train, steps_per_epoch=60000 // 32, epochs=5, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "keras_layer (KerasLayer)     (None, 50)                48190600  \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                816       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 48,191,433\n",
      "Trainable params: 833\n",
      "Non-trainable params: 48,190,600\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "hub_layer = hub.KerasLayer(\"https://tfhub.dev/google/tf2-preview/nnlm-en-dim50/1\",\n",
    "                           output_shape=[50], input_shape=[], dtype=tf.string)\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(hub_layer)\n",
    "model.add(keras.layers.Dense(16, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = tf.constant([\"It was a great movie\", \"The actors were amazing\"])\n",
    "embeddings = hub_layer(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 50), dtype=float32, numpy=\n",
       "array([[ 7.45939985e-02,  2.76720114e-02,  9.38646123e-02,\n",
       "         1.25124469e-01,  5.40293928e-04, -1.09435350e-01,\n",
       "         1.34755149e-01, -9.57818255e-02, -1.85177118e-01,\n",
       "        -1.69703495e-02,  1.75612606e-02, -9.06603858e-02,\n",
       "         1.12110220e-01,  1.04646273e-01,  3.87700424e-02,\n",
       "        -7.71859884e-02, -3.12189370e-01,  6.99466765e-02,\n",
       "        -4.88970093e-02, -2.99049795e-01,  1.31183028e-01,\n",
       "        -2.12630898e-01,  6.96169436e-02,  1.63592950e-01,\n",
       "         1.05169769e-02,  7.79720694e-02, -2.55230188e-01,\n",
       "        -1.80790052e-01,  2.93739915e-01,  1.62875261e-02,\n",
       "        -2.80566931e-01,  1.60284728e-01,  9.87277832e-03,\n",
       "         8.44555616e-04,  8.39456245e-02,  3.24002892e-01,\n",
       "         1.53253034e-01, -3.01048346e-02,  8.94618109e-02,\n",
       "        -2.39153411e-02, -1.50188789e-01, -1.81733668e-02,\n",
       "        -1.20483577e-01,  1.32937476e-01, -3.35325629e-01,\n",
       "        -1.46504581e-01, -1.25251599e-02, -1.64428815e-01,\n",
       "        -7.00765476e-02,  3.60923223e-02],\n",
       "       [-1.56998575e-01,  4.24599349e-02, -5.57703003e-02,\n",
       "        -8.08446854e-03,  1.23733155e-01,  3.89427543e-02,\n",
       "        -4.37901802e-02, -1.86987907e-01, -2.29341656e-01,\n",
       "        -1.27766818e-01,  3.83025259e-02, -1.07057482e-01,\n",
       "        -6.11584112e-02,  2.49654502e-01, -1.39712945e-01,\n",
       "        -3.91289443e-02, -1.35873526e-01, -3.58613044e-01,\n",
       "         2.53462754e-02, -1.58370987e-01, -1.38350084e-01,\n",
       "        -3.90771806e-01, -6.63642734e-02, -3.24838236e-02,\n",
       "        -2.20453963e-02, -1.68282315e-01, -7.40613639e-02,\n",
       "        -2.49074101e-02,  2.46460736e-01,  9.87201929e-05,\n",
       "        -1.85390845e-01, -4.92824614e-02,  1.09015472e-01,\n",
       "        -9.54203904e-02, -1.60352528e-01, -2.59811729e-02,\n",
       "         1.13778859e-01, -2.09578887e-01,  2.18261331e-01,\n",
       "        -3.11211571e-02, -6.12562597e-02, -8.66057724e-02,\n",
       "        -1.10762455e-01, -5.73977083e-03, -1.08923554e-01,\n",
       "        -1.72919363e-01,  1.00515485e-01, -5.64153939e-02,\n",
       "        -4.97694984e-02, -1.07776590e-01]], dtype=float32)>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "nav_menu": {
   "height": "264px",
   "width": "369px"
  },
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
